# @package _global_

# to execute this experiment run:
# python train.py experiment=example

defaults:
  - override /datamodule: seg.yaml
  - override /model: seg.yaml
  - override /callbacks: default.yaml
  - override /trainer: default.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

task_name: "train_seg_SWET_skin_base"

seg_type: "skin"

auto_crop: False

perturbation: "base"

dataset: "SWET"

tags: ["seg", "skin", "base", "SWET", "UNet"]

seed: 37

trainer:
  accelerator: gpu
  devices: 1
  min_epochs: 10
  max_epochs: 50
  gradient_clip_val: 0.5

datamodule:
  batch_size: 2
  seg_type: ${seg_type}

model:
  optimizer:
    lr: 0.001
    momentum: 0.9
    weight_decay: 0.005
  scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
    mode: max
    factor: 0.3
    patience: 5
  monitor: "val/IoU"
  auto_crop: ${auto_crop}
  encoder_name: efficientnet_b3

callbacks:
  model_checkpoint:
    monitor: "val/IoU"
    mode: "max"
    save_last: True
    auto_insert_metric_name: False
  early_stopping:
    monitor: "val/IoU"
    patience: 10
    mode: "max"

logger:
  wandb:
    tags: ${tags}
    project: "ENET_seg"
    group: ${task_name}
    id: null # pass correct id to resume experiment!
